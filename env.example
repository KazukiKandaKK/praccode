# ===========================================
# PracCode 環境変数設定
# ===========================================
# このファイルを .env にコピーして使用してください
# cp env.example .env
#
# 注意: Docker環境では docker-compose.dev.yml の environment セクションで
#       設定するか、ホストの .env ファイルを参照します。
#       ローカル環境では apps/backend/.env と apps/frontend/.env.local に
#       それぞれ設定が必要です。

# LLM Provider設定（ollama または gemini）
# デフォルト: gemini（API Key）
LLM_PROVIDER=gemini
GEMINI_AUTH_MODE=api_key
GEMINI_API_KEY=your-gemini-api-key

# Ollama設定（LLM_PROVIDER=ollamaの場合）
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:7b
# 長い生成が発生する場合のタイムアウト（ms）
OLLAMA_TIMEOUT_MS=240000

# Gemini設定（共通）
GEMINI_MODEL=gemini-2.5-flash-lite

# Vertex AI を使う場合（任意）
# GEMINI_AUTH_MODE=vertex
# GOOGLE_CLOUD_PROJECT=your-gcp-project-id
# GOOGLE_CLOUD_LOCATION=us-central1
# GOOGLE_APPLICATION_CREDENTIALS_FILE=./secrets/gcp-sa.json

# OpenAI API Key
# OPENAI_API_KEY=sk-your-openai-api-key
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=https://api.openai.com/v1

# LLMレート制限設定
# 60秒で10リクエスト/60000トークンを上限とし、上限到達の10秒前で縮退
LLM_RATE_LIMIT_WINDOW_MS=60000
LLM_RATE_LIMIT_MAX_REQUESTS=10
LLM_RATE_LIMIT_MAX_TOKENS=60000
LLM_RATE_LIMIT_PREEMPT_MS=10000
LLM_RATE_LIMIT_MAX_RETRIES=3

# Agent OS設定
AGENT_STEP_LIMIT=12
AGENT_PARALLEL_PLANS=3
AGENT_GUARD_LLM=false
ENABLE_WEB_SEARCH=false

# NextAuth.js 設定
# 本番環境では必ず強力なシークレットを設定してください
# openssl rand -base64 32 で生成できます
NEXTAUTH_SECRET=your-nextauth-secret-key

# データベース (Docker使用時は変更不要)
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/praccode?schema=public
